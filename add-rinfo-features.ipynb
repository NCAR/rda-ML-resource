{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secondary-wisdom",
   "metadata": {},
   "source": [
    "# Goal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-family",
   "metadata": {},
   "source": [
    "For the entries in the \"job metrics\" dataframe which have rinfo strings,\n",
    "extract all the information from those rinfo strings and add that information to the \n",
    "dataframe in the form of new columns. \n",
    "\n",
    "This includes parsing data from the rinfo strings and converting to the appropriate format.\n",
    "\n",
    "Then decide which columns to include in the training dataframe that will be passed to the\n",
    "ML model. After rearranging and renaming those columns, save to a .pkl file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-taylor",
   "metadata": {},
   "source": [
    "# Imports and display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crazy-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-planning",
   "metadata": {},
   "source": [
    "# Selecting features to extract from rinfo strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-atmosphere",
   "metadata": {},
   "source": [
    "The list of all features we will extract from the rinfo strings is contained in rinfo-features.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considered-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dates', 'dsnum', 'elon', 'enddate', 'format', 'grid_definition', 'gui', 'lats', 'level', 'lons', 'nlat', 'parameters', 'product', 'slat', 'startdate', 'station', 'tindex', 'wlon']\n"
     ]
    }
   ],
   "source": [
    "feature_names_file = open(\"rinfo-features.txt\")\n",
    "all_rinfo_features = feature_names_file.read().split('\\n')\n",
    "\n",
    "print(all_rinfo_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-simon",
   "metadata": {},
   "source": [
    "Some features are entered with slightly different syntax in different rinfo strings.\n",
    "\n",
    "For example : grid definition may appear as either \"grid_definition\" or \"grid-definition\".\n",
    "\n",
    "The next cell solves this problem by making a dictionary containing lists of alternate\n",
    "names for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blind-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_features = ['grid_definition', 'params', 'format']\n",
    "normal_features = [feat for feat in all_rinfo_features\n",
    "                   if feat not in special_features]\n",
    "\n",
    "special_alt_names = {'grid_definition': ['grid_definition', 'grid-definition'],\n",
    "                     'parameters': ['parameters', 'params', 'parms'],\n",
    "                     'format': ['format', 'ofmt', 'fmt'],\n",
    "                     'tindex': ['tindex', 'gindex']}\n",
    "\n",
    "alternate_names = {feat: [feat] for feat in normal_features}\n",
    "alternate_names.update(special_alt_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-monroe",
   "metadata": {},
   "source": [
    "# Functions that parse rinfo strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rotary-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_rinfo_val(feature, val):\n",
    "    \"\"\"Decides the appropriate 'null value' for when a feature is\n",
    "    not present in an rinfo string.\n",
    "    \"\"\"\n",
    "\n",
    "    if feature == 'gui':\n",
    "        return False\n",
    "    elif feature in ['startdate', 'enddate']:\n",
    "        return pd.NaT\n",
    "    else:\n",
    "        return float('nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sublime-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rinfo_val(rinfo, feature, val):\n",
    "    \"\"\"Formats a value found in an rinfo string so that it can be entered\n",
    "    correctly into the pandas dataframe.\n",
    "    \n",
    "    Example input: \n",
    "    rinfo = '...;elon=76.4;...'\n",
    "    feature = 'elon'\n",
    "    val = '76.4'\n",
    "\n",
    "    Example output: 76.4\n",
    "    \"\"\"\n",
    "\n",
    "    if val == '':\n",
    "        return handle_missing_rinfo_val(feature, val)\n",
    "\n",
    "    try:\n",
    "        if feature in ['elon', 'wlon', 'nlat', 'slat']:\n",
    "            return float(val)\n",
    "        elif feature in ['startdate', 'enddate']:\n",
    "            return pd.to_datetime(val, errors='coerce')\n",
    "        elif feature in ['gindex', 'tindex']:\n",
    "            return float(val)\n",
    "        elif feature == 'gui':\n",
    "            return True if val == 'yes' else False\n",
    "        else:\n",
    "            return val\n",
    "    except:\n",
    "        failed_parse.write(f\"Could not parse {feature} from {val}. \\n\")\n",
    "        failed_parse.write(f\"rinfo string: {rinfo} \\n\")\n",
    "        return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "close-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_from_rinfo(rinfo, feature):\n",
    "    \"\"\"Finds the value of the given feature in the given rinfo string.\n",
    "    If the feature is not present in rinfo, calls handle_missing_rinfo_val.\n",
    "    If the feature is present, uses format_rinfo_val to convert the value \n",
    "    to the appropriate data type before returning.\n",
    "    \n",
    "    Example input: \n",
    "    rinfo = '...;elon=76.4;...' \n",
    "    feature = 'elon'\n",
    "\n",
    "    Example output: 76.4\n",
    "    \"\"\"\n",
    "    \n",
    "    rinfo = rinfo.replace('%3D', '=')\n",
    "    \n",
    "    if ';' in rinfo:\n",
    "        sep = ';'\n",
    "    else:\n",
    "        sep = '&'\n",
    "\n",
    "    val = ''\n",
    "    for alternate_name in alternate_names[feature]:\n",
    "        if rinfo.lower().find(alternate_name) != -1:\n",
    "            start_ind = rinfo.lower().find(alternate_name) + len(alternate_name) + 1\n",
    "            end_ind = rinfo.find(sep, start_ind)\n",
    "            if end_ind != -1:\n",
    "                val = rinfo[start_ind:end_ind]\n",
    "            else:\n",
    "                val = rinfo[start_ind:]\n",
    "                \n",
    "    val = format_rinfo_val(rinfo, feature, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-rates",
   "metadata": {},
   "source": [
    "# Parsing rinfo strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "textile-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_rinfo(rinfo):\n",
    "    \"\"\"Decides whether an rinfo string is 'valid.'\n",
    "    In practice, just serves to filter out a few problematic rinfo strings\n",
    "    (14 out of the original 59803, or 0.023%).\n",
    "    \"\"\"\n",
    "    if '\\\\n' in rinfo:\n",
    "        return False\n",
    "    elif '76,78,81,83,85,88,90,92,94,96grid_definition' in rinfo:\n",
    "        return False\n",
    "    elif 'startDate' in rinfo:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-lodging",
   "metadata": {},
   "source": [
    "First read in the dataframe and filter out those which have missing or invalid rinfo strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "backed-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/glade/work/jdubeau/job-metrics-data.pkl')\n",
    "df = df[df.rinfo.notnull()]\n",
    "df['valid_rinfo'] = df.apply(lambda row: valid_rinfo(row['rinfo']), axis = 1)\n",
    "df = df[df.valid_rinfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fuzzy-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start_date',\n",
       " 'end_date',\n",
       " 'status',\n",
       " 'req_mem',\n",
       " 'used_mem',\n",
       " 'mem_delta',\n",
       " 'percent_mem',\n",
       " 'dsid',\n",
       " 'request_type',\n",
       " 'request_id',\n",
       " 'partition_id',\n",
       " 'rinfo',\n",
       " 'cpus',\n",
       " 'valid_rinfo']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-patrol",
   "metadata": {},
   "source": [
    "Now add all the rinfo features as new columns. In case of any parsing errors, we\n",
    "keep track of the rinfo strings that failed to parse in a file called failed-parse.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "judicial-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_parse = open('failed-parse.txt', 'w')\n",
    "\n",
    "for feature in all_rinfo_features:\n",
    "    df[feature] = df.apply(lambda row: get_val_from_rinfo(row['rinfo'], feature), axis = 1)\n",
    "\n",
    "failed_parse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "objective-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59789 entries, 6132011 to 6785820\n",
      "Data columns (total 32 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   start_date       59789 non-null  object        \n",
      " 1   end_date         59789 non-null  object        \n",
      " 2   status           59789 non-null  object        \n",
      " 3   req_mem          59789 non-null  int64         \n",
      " 4   used_mem         59789 non-null  float64       \n",
      " 5   mem_delta        59789 non-null  float64       \n",
      " 6   percent_mem      59789 non-null  float64       \n",
      " 7   dsid             59789 non-null  object        \n",
      " 8   request_type     59789 non-null  object        \n",
      " 9   request_id       59789 non-null  float64       \n",
      " 10  partition_id     45927 non-null  float64       \n",
      " 11  rinfo            59789 non-null  object        \n",
      " 12  cpus             56549 non-null  float64       \n",
      " 13  valid_rinfo      59789 non-null  bool          \n",
      " 14  dates            12929 non-null  object        \n",
      " 15  dsnum            57192 non-null  object        \n",
      " 16  elon             35799 non-null  float64       \n",
      " 17  enddate          57065 non-null  datetime64[ns]\n",
      " 18  format           24420 non-null  object        \n",
      " 19  grid_definition  10790 non-null  object        \n",
      " 20  gui              59789 non-null  bool          \n",
      " 21  lats             2188 non-null   object        \n",
      " 22  level            26485 non-null  object        \n",
      " 23  lons             2188 non-null   object        \n",
      " 24  nlat             35778 non-null  float64       \n",
      " 25  parameters       59507 non-null  object        \n",
      " 26  product          25995 non-null  object        \n",
      " 27  slat             35778 non-null  float64       \n",
      " 28  startdate        57176 non-null  datetime64[ns]\n",
      " 29  station          403 non-null    object        \n",
      " 30  tindex           21283 non-null  float64       \n",
      " 31  wlon             35799 non-null  float64       \n",
      "dtypes: bool(2), datetime64[ns](2), float64(11), int64(1), object(16)\n",
      "memory usage: 14.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-clinic",
   "metadata": {},
   "source": [
    "# Combining redundant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-layer",
   "metadata": {},
   "source": [
    "The first redundancy we deal with are the columns called \"lats\" and \"lons.\" \n",
    "A \"lats\" entry, for example, would look like \"60 S 80 N.\" This information should\n",
    "be split up and entered into the \"slat\" and \"nlat\" columns in the same row, by \n",
    "setting slat = -60.0 and nlat = 80.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "derived-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lats_lons(val):\n",
    "    \"\"\"Takes a 'lats' or 'lons' value and returns two floats representing the \n",
    "    southern/western coordinate and the northern/eastern coordinate.\n",
    "    Example input: '60 S 80 N'\n",
    "    Example output: (-60.0, 80.0)\n",
    "    \"\"\"\n",
    "    val = val.replace(',', '')\n",
    "    substrings = val.split(' ')\n",
    "\n",
    "    try:\n",
    "        first_coord = float(substrings[0])\n",
    "        second_coord = float(substrings[2])\n",
    "    except:\n",
    "        print(f\"Error expanding lats/lons. Value = {val}\")\n",
    "        return float('nan')\n",
    "\n",
    "    if substrings[1] == 'W' or substrings[1] == 'S':\n",
    "        first_coord = -1*first_coord\n",
    "    if substrings[3] == 'W' or substrings[3] == 'S':\n",
    "        second_coord = -1*second_coord\n",
    "\n",
    "    return (first_coord, second_coord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reliable-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lat_lon(feature, row):\n",
    "    \"\"\"Used to update 'slat', 'nlat', 'wlon', or 'elon' by \n",
    "    getting the values from 'lats' or 'lons' in the same row.\n",
    "    Example input: ('nlat', <row containing 'lats=45 S 50 N'>)\n",
    "    Example output: 50.0\n",
    "    \"\"\"\n",
    "    if row['lats'] != row['lats']:\n",
    "        return row[feature]\n",
    "    else:\n",
    "        if feature == 'slat':\n",
    "            return parse_lats_lons(row['lats'])[0]\n",
    "        elif feature == 'nlat':\n",
    "            return parse_lats_lons(row['lats'])[1]\n",
    "        elif feature == 'wlon':\n",
    "            return parse_lats_lons(row['lons'])[0]\n",
    "        else:\n",
    "            return parse_lats_lons(row['lons'])[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-grant",
   "metadata": {},
   "source": [
    "Compare the df.info() output with the previous df.info(); there should be more non-null slat's, nlat's, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "victorian-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59789 entries, 6132011 to 6785820\n",
      "Data columns (total 32 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   start_date       59789 non-null  object        \n",
      " 1   end_date         59789 non-null  object        \n",
      " 2   status           59789 non-null  object        \n",
      " 3   req_mem          59789 non-null  int64         \n",
      " 4   used_mem         59789 non-null  float64       \n",
      " 5   mem_delta        59789 non-null  float64       \n",
      " 6   percent_mem      59789 non-null  float64       \n",
      " 7   dsid             59789 non-null  object        \n",
      " 8   request_type     59789 non-null  object        \n",
      " 9   request_id       59789 non-null  float64       \n",
      " 10  partition_id     45927 non-null  float64       \n",
      " 11  rinfo            59789 non-null  object        \n",
      " 12  cpus             56549 non-null  float64       \n",
      " 13  valid_rinfo      59789 non-null  bool          \n",
      " 14  dates            12929 non-null  object        \n",
      " 15  dsnum            57192 non-null  object        \n",
      " 16  elon             37987 non-null  float64       \n",
      " 17  enddate          57065 non-null  datetime64[ns]\n",
      " 18  format           24420 non-null  object        \n",
      " 19  grid_definition  10790 non-null  object        \n",
      " 20  gui              59789 non-null  bool          \n",
      " 21  lats             2188 non-null   object        \n",
      " 22  level            26485 non-null  object        \n",
      " 23  lons             2188 non-null   object        \n",
      " 24  nlat             37966 non-null  float64       \n",
      " 25  parameters       59507 non-null  object        \n",
      " 26  product          25995 non-null  object        \n",
      " 27  slat             37966 non-null  float64       \n",
      " 28  startdate        57176 non-null  datetime64[ns]\n",
      " 29  station          403 non-null    object        \n",
      " 30  tindex           21283 non-null  float64       \n",
      " 31  wlon             37987 non-null  float64       \n",
      "dtypes: bool(2), datetime64[ns](2), float64(11), int64(1), object(16)\n",
      "memory usage: 14.3+ MB\n"
     ]
    }
   ],
   "source": [
    "for feature in ['slat', 'nlat', 'wlon', 'elon']:\n",
    "    df[feature] = df.apply(lambda row: update_lat_lon(feature, row), axis = 1)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-observer",
   "metadata": {},
   "source": [
    "Next we deal with the 'dates' column. Here there are three possibilities:\n",
    "\n",
    "1. The 'dates' field contains two dates, representing a start and end date, \n",
    "e.g. \"dates=2019-01-01 00:00 2019-12-31 18:00\"\n",
    "\n",
    "2. The 'dates' field says the dates were initial (as opposed to valid),\n",
    "e.g. \"dates=init\"\n",
    "\n",
    "3. The 'dates' field was empty, indicating that the dates were valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "swedish-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(feature, dates):\n",
    "    \"\"\"Deduces a start date or end date from whatever was in\n",
    "    the 'dates' column. The entered feature must be either \n",
    "    'startdate' or 'enddate'.\n",
    "    Example input: ('enddate', '2019-01-01 00:00 2019-12-31 18:00')\n",
    "    Example output: 2019-12-31 18:00 (pandas datetime object)\n",
    "    \"\"\"\n",
    "    dates_split = dates.split(' ')\n",
    "        \n",
    "    if len(dates_split) == 4:\n",
    "        # Typical case: dates=2019-01-01 00:00 2019-12-31 18:00\n",
    "        if feature == 'startdate':\n",
    "            date = dates_split[0] + ' ' + dates_split[1]\n",
    "        else:\n",
    "            date = dates_split[2] + ' ' + dates_split[3]\n",
    "    else:\n",
    "        # Typical cases: either dates=1806-01-01 1900-12-31\n",
    "        # or dates=197005 201412\n",
    "        if feature == 'startdate':\n",
    "            date = dates_split[0]\n",
    "        else:\n",
    "            date = dates_split[1]\n",
    "            \n",
    "        if '-' not in dates_split[0]:\n",
    "            date = date[:4] + '-' + date[4:]\n",
    "                \n",
    "    return pd.to_datetime(date, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sacred-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dates(feature, row):\n",
    "    \"\"\"Used to update 'startdate', 'enddate', or 'dates_init' by\n",
    "    getting the values from the 'dates' column in the same row.\n",
    "    feature must be either 'startdate', 'enddate', or 'dates_init'.\n",
    "    \"\"\"\n",
    "    dates = row['dates']\n",
    "    \n",
    "    if feature == 'dates_init':\n",
    "        return True if dates == 'init' else False\n",
    "\n",
    "    if row[feature] == row[feature]:\n",
    "        return row[feature]\n",
    "    else:\n",
    "        if row['dates'] == row['dates'] and row['dates'] != 'init':\n",
    "            return parse_dates(feature, dates)\n",
    "        else:\n",
    "            return pd.NaT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-simpson",
   "metadata": {},
   "source": [
    "Again, after we combine the info from 'dates', there should be more\n",
    "non-null 'startdate's and 'enddates' compared to the previous df.info() call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "latest-deputy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59789 entries, 6132011 to 6785820\n",
      "Data columns (total 33 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   start_date       59789 non-null  object        \n",
      " 1   end_date         59789 non-null  object        \n",
      " 2   status           59789 non-null  object        \n",
      " 3   req_mem          59789 non-null  int64         \n",
      " 4   used_mem         59789 non-null  float64       \n",
      " 5   mem_delta        59789 non-null  float64       \n",
      " 6   percent_mem      59789 non-null  float64       \n",
      " 7   dsid             59789 non-null  object        \n",
      " 8   request_type     59789 non-null  object        \n",
      " 9   request_id       59789 non-null  float64       \n",
      " 10  partition_id     45927 non-null  float64       \n",
      " 11  rinfo            59789 non-null  object        \n",
      " 12  cpus             56549 non-null  float64       \n",
      " 13  valid_rinfo      59789 non-null  bool          \n",
      " 14  dates            12929 non-null  object        \n",
      " 15  dsnum            57192 non-null  object        \n",
      " 16  elon             37987 non-null  float64       \n",
      " 17  enddate          59661 non-null  datetime64[ns]\n",
      " 18  format           24420 non-null  object        \n",
      " 19  grid_definition  10790 non-null  object        \n",
      " 20  gui              59789 non-null  bool          \n",
      " 21  lats             2188 non-null   object        \n",
      " 22  level            26485 non-null  object        \n",
      " 23  lons             2188 non-null   object        \n",
      " 24  nlat             37966 non-null  float64       \n",
      " 25  parameters       59507 non-null  object        \n",
      " 26  product          25995 non-null  object        \n",
      " 27  slat             37966 non-null  float64       \n",
      " 28  startdate        59748 non-null  datetime64[ns]\n",
      " 29  station          403 non-null    object        \n",
      " 30  tindex           21283 non-null  float64       \n",
      " 31  wlon             37987 non-null  float64       \n",
      " 32  dates_init       59789 non-null  bool          \n",
      "dtypes: bool(3), datetime64[ns](2), float64(11), int64(1), object(16)\n",
      "memory usage: 14.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "date_features = ['dates_init', 'startdate', 'enddate']\n",
    "for feature in date_features:\n",
    "    df[feature] = df.apply(lambda row: update_dates(feature, row), axis = 1)\n",
    "    \n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-tyler",
   "metadata": {},
   "source": [
    "# Final cleaning and saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-amazon",
   "metadata": {},
   "source": [
    "At the moment, 'start_date' refers to the date/time that the SLURM job began, whereas 'startdate' refers to the date/time that the requested data starts from. We rename those two to avoid confusion. We do the same for 'end_date' and 'enddate.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "framed-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'start_date': 'job_start',\n",
    "                        'end_date': 'job_end',\n",
    "                        'enddate': 'rqst_end',\n",
    "                        'startdate': 'rqst_start'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "virgin-mayor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_start',\n",
       " 'job_end',\n",
       " 'status',\n",
       " 'req_mem',\n",
       " 'used_mem',\n",
       " 'mem_delta',\n",
       " 'percent_mem',\n",
       " 'dsid',\n",
       " 'request_type',\n",
       " 'request_id',\n",
       " 'partition_id',\n",
       " 'rinfo',\n",
       " 'cpus',\n",
       " 'valid_rinfo',\n",
       " 'dates',\n",
       " 'dsnum',\n",
       " 'elon',\n",
       " 'rqst_end',\n",
       " 'format',\n",
       " 'grid_definition',\n",
       " 'gui',\n",
       " 'lats',\n",
       " 'level',\n",
       " 'lons',\n",
       " 'nlat',\n",
       " 'parameters',\n",
       " 'product',\n",
       " 'slat',\n",
       " 'rqst_start',\n",
       " 'station',\n",
       " 'tindex',\n",
       " 'wlon',\n",
       " 'dates_init']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "latin-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = ['request_type', 'job_start',\n",
    "                     'job_end', 'req_mem', 'used_mem',\n",
    "                     'mem_delta', 'percent_mem',\n",
    "                     'dsnum', 'rqst_start', 'rqst_end',\n",
    "                     'dates_init', 'slat',\n",
    "                     'nlat', 'wlon', 'elon', 'gui',\n",
    "                     'parameters', 'level', 'product',\n",
    "                     'station', 'tindex'] \n",
    "\n",
    "training_df = df[training_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "increasing-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59789 entries, 6132011 to 6785820\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   request_type  59789 non-null  object        \n",
      " 1   job_start     59789 non-null  object        \n",
      " 2   job_end       59789 non-null  object        \n",
      " 3   req_mem       59789 non-null  int64         \n",
      " 4   used_mem      59789 non-null  float64       \n",
      " 5   mem_delta     59789 non-null  float64       \n",
      " 6   percent_mem   59789 non-null  float64       \n",
      " 7   dsnum         57192 non-null  object        \n",
      " 8   rqst_start    59748 non-null  datetime64[ns]\n",
      " 9   rqst_end      59661 non-null  datetime64[ns]\n",
      " 10  dates_init    59789 non-null  bool          \n",
      " 11  slat          37966 non-null  float64       \n",
      " 12  nlat          37966 non-null  float64       \n",
      " 13  wlon          37987 non-null  float64       \n",
      " 14  elon          37987 non-null  float64       \n",
      " 15  gui           59789 non-null  bool          \n",
      " 16  parameters    59507 non-null  object        \n",
      " 17  level         26485 non-null  object        \n",
      " 18  product       25995 non-null  object        \n",
      " 19  station       403 non-null    object        \n",
      " 20  tindex        21283 non-null  float64       \n",
      "dtypes: bool(2), datetime64[ns](2), float64(8), int64(1), object(8)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "swiss-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '/glade/work/jdubeau/job-metrics-training.pkl'\n",
    "training_df.to_pickle(training_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
