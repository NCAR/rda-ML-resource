{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e11c66-6378-4494-bd84-90ffca506a2c",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512010c-6e20-4a39-bfbf-8e690de8187c",
   "metadata": {},
   "source": [
    "This notebook is used to train classifiers to predict used memory, and then save the trained model along with the data it used. This includes a decision tree, a random forest, a gradient boosted decision tree model, and a logistic regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b87cb7-01e5-4bcf-9ae1-d66bb40a2ded",
   "metadata": {},
   "source": [
    "# Notebook options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f1d8f6-521a-40bc-ba3e-8693f4eaaf63",
   "metadata": {},
   "source": [
    "The grid_search parameter determines whether the notebook will execute a grid search for each model to find the best combination of hyperparameters, or whether the notebook will just use some pre-set parameters (which were found in previous grid searches).\n",
    "\n",
    "The save_model parameter determines whether to save a model at the end (currently it saves the random forest model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea92a0f7-d0e4-4ebe-9e9f-76acddb02b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ad1f4-51c5-4269-b4c0-250b5415769b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c154bd-6209-4f8f-8575-4f0600cfa615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from hypopt import GridSearch\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from preprocessing import get_df\n",
    "from preprocessing import scale\n",
    "from persistence import save_trained_model\n",
    "from evaluation import score_model\n",
    "from evaluation import print_feature_importances\n",
    "from evaluation import plot_performance\n",
    "from evaluation import plot_cm\n",
    "from evaluation import print_cr\n",
    "from evaluation import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c87db0-1e63-417a-8806-742196e40eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc3144c-4215-4dc7-9ef1-b49cf7c25420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f638e5-f702-40f8-b9d5-45c8c94bf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bin_cutoffs = [50, 100, 200, 500, 1000, 2000, 10000, 20000, 50000, 100000]\n",
    "num_classes = len(mem_bin_cutoffs)\n",
    "bin_sizes = [df[df.used_mem < mem_bin_cutoffs[0]].shape[0]]\n",
    "for i in range(1, len(mem_bin_cutoffs)):\n",
    "    current_bin_size = df[(df.used_mem >= mem_bin_cutoffs[i-1])\n",
    "                        & (df.used_mem < mem_bin_cutoffs[i])].shape[0]\n",
    "    bin_sizes.append(current_bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a5ade9-8720-46fc-89db-57c188874fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mem_categories():\n",
    "    print(f\"0: < {mem_bin_cutoffs[0]}MB ({bin_sizes[0]} entries)\")\n",
    "    for i in range(1, len(mem_bin_cutoffs)):\n",
    "        print(f\"{i}: >= {mem_bin_cutoffs[i-1]}MB\"\n",
    "              + f\" and < {mem_bin_cutoffs[i]}MB\"\n",
    "              + f\" ({bin_sizes[i]} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cdaf8a6-ecec-4146-a8cf-86cb24945c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: < 50MB (22965 entries)\n",
      "1: >= 50MB and < 100MB (11126 entries)\n",
      "2: >= 100MB and < 200MB (8623 entries)\n",
      "3: >= 200MB and < 500MB (3169 entries)\n",
      "4: >= 500MB and < 1000MB (1639 entries)\n",
      "5: >= 1000MB and < 2000MB (2535 entries)\n",
      "6: >= 2000MB and < 10000MB (248 entries)\n",
      "7: >= 10000MB and < 20000MB (33 entries)\n",
      "8: >= 20000MB and < 50000MB (22 entries)\n",
      "9: >= 50000MB and < 100000MB (0 entries)\n"
     ]
    }
   ],
   "source": [
    "print_mem_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bccffa-af58-43ca-85bd-b90736b285b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_category(row):\n",
    "    mem = row['used_mem']\n",
    "    if mem < mem_bin_cutoffs[0]:\n",
    "        return 0\n",
    "    for i in range(1, len(mem_bin_cutoffs)):\n",
    "        if mem >= mem_bin_cutoffs[i-1] and mem < mem_bin_cutoffs[i]:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02823e78-c8f3-4796-adf8-db44c2284dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mem_category'] = df.apply(lambda row: mem_category(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49cd37f4-861b-42b6-bcab-5ef6540e6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.rqst_timespan.notnull() & df.rqst_area_rect.notnull()]\n",
    "X_features = ['PP', 'SP', 'BR', 'rqst_timespan', 'rqst_area_rect', 'converted',\n",
    "              'params_num', 'grid_def_num', 'level_num',\n",
    "              'ds084.1', 'ds631.1', 'ds083.3', 'ds094.0', 'ds083.2']\n",
    "y_features = ['req_mem', 'used_mem', 'mem_category']\n",
    "\n",
    "X = df[X_features]\n",
    "y = df[y_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf78d5e7-ca51-4adc-84f8-020a2e00c995",
   "metadata": {},
   "source": [
    "## Train/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ae54b0-125b-4ba3-8f24-61b2cf89595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amt = 0.5\n",
    "val_amt = 0.25\n",
    "test_amt = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c8ad88f-fc10-47af-9e2a-28a973a5eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_target, y_train_full, y_target_full = \\\n",
    "                train_test_split(X, y, \n",
    "                test_size=1-train_amt, \n",
    "                random_state = 3)\n",
    "X_val, X_test, y_val_full, y_test_full = \\\n",
    "                train_test_split(X_target, y_target_full,\n",
    "                                 test_size = test_amt/train_amt,\n",
    "                                 random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99acf27-0f46-495e-a807-d198222e7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train_full['mem_category'])\n",
    "y_val = np.ravel(y_val_full['mem_category'])\n",
    "y_test = np.ravel(y_test_full['mem_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e93f45-8f55-447a-a2ab-6f1170104d06",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "855b00ce-5a00-4ea1-a2c8-0699ce44960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm, X_val_norm, X_test_norm = \\\n",
    "    scale(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd8c2c1-73b2-45ea-949a-80af8fb72ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_score(y, y_pred, **kwargs):\n",
    "    n_samples = X_train.shape[0]\n",
    "    class_weights = n_samples / ((num_classes - 1) * (np.bincount(y_train)))\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i]:\n",
    "            score += class_weights[y[i]]\n",
    "        \n",
    "    return score\n",
    "\n",
    "balanced_scorer = make_scorer(score_func=balanced_score,\n",
    "                              greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5110a-ace6-429b-85be-466614642c09",
   "metadata": {},
   "source": [
    "## Trees, Forest, Gradient Boosts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af00f3-185c-47d9-a64d-ee833aaafde7",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb07249-899c-4cda-947f-a050c75d7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    tree_param_grid = {'random_state':[3], 'max_depth':range(2,20),\n",
    "                       'class_weight':['balanced']}\n",
    "    tree_gs = GridSearch(model=DecisionTreeClassifier(), \n",
    "                              param_grid=tree_param_grid,\n",
    "                              parallelize=False)\n",
    "    tree_gs.fit(X_train_norm, y_train, X_val_norm, y_val, scoring=balanced_scorer)\n",
    "    print(tree_gs.best_params)\n",
    "    tree = tree_gs.best_estimator_\n",
    "\n",
    "else:\n",
    "    tree = DecisionTreeClassifier(class_weight='balanced',\n",
    "                                  max_depth=19, random_state=3)\n",
    "    tree.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2c8ab-e0db-4b5b-bf27-8e627aad5a75",
   "metadata": {},
   "source": [
    "### Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b3e4f7f-95bd-4ae2-84e0-1a071cf7728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    forest_param_grid = {'random_state':[3],\n",
    "                               'max_depth':range(2,15),\n",
    "                               'min_samples_split':range(2,8),\n",
    "                               'n_estimators':[100,200,300,500],\n",
    "                               'class_weight':['balanced', 'balanced_subsample']}\n",
    "    forest_gs = GridSearch(model=RandomForestClassifier(), \n",
    "                                param_grid=forest_param_grid,\n",
    "                                parallelize=False)\n",
    "    forest_gs.fit(X_train_norm, y_train, X_val_norm, y_val, scoring=balanced_scorer)\n",
    "    print(forest_gs.best_params)\n",
    "    forest = forest_gs.best_estimator_\n",
    "else:\n",
    "    forest = RandomForestClassifier(class_weight='balanced',\n",
    "                                      max_depth=12,\n",
    "                                      min_samples_split=5,\n",
    "                                      n_estimators=100,\n",
    "                                      random_state=3)\n",
    "    forest.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8a78f-723e-49ce-be23-950c05bd84ab",
   "metadata": {},
   "source": [
    "### Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "613558b7-d8b2-474a-91ce-b5f5108b0cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    gboost_param_grid = {'random_state':[3],\n",
    "                               'max_depth':range(2,15),\n",
    "                               'n_estimators':[100,200,300,500]}\n",
    "    gboost_gs = GridSearch(model=GradientBoostingClassifier(), \n",
    "                                param_grid=gboost_param_grid,\n",
    "                                parallelize=False)\n",
    "    gboost_gs.fit(X_train_norm, y_train, X_val_norm, y_val)\n",
    "    print(class_gboost_gs.best_params)\n",
    "    class_gboost = class_gboost_gs.best_estimator_\n",
    "else:\n",
    "    gboost = GradientBoostingClassifier(random_state=3,\n",
    "                                        max_depth=14,\n",
    "                                        n_estimators=150)\n",
    "    gboost.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011d694-fa96-4dd8-870a-e3395096bce3",
   "metadata": {},
   "source": [
    "## Linear regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68999ddf-a8ec-47e4-a245-a7f09475bcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logist = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "logist.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d82c4723-693a-451d-9772-8ce7b193a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model:\n",
    "    save_trained_model('class_forest', \n",
    "                   forest, df, \n",
    "                   X_features,\n",
    "                   X_train_norm, y_train_full,\n",
    "                   X_val_norm, y_val_full,\n",
    "                   X_test_norm, y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec308b-a890-403f-aa8c-997bf4a5e82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fixed-python-path",
   "language": "python",
   "name": "fixed-python-path"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
