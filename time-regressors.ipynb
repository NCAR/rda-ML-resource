{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750e8c82-9149-4427-b6e6-df8b71e5078b",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f337300-cde6-4d4f-b564-509548130ee2",
   "metadata": {},
   "source": [
    "This notebook is used to \n",
    "\n",
    "1. Train regressors to predict THE LOGARITHM OF the wall time, and then \n",
    "\n",
    "2. Save the trained model along with the data it used. \n",
    "\n",
    "This includes a decision tree, a random forest, a gradient boosted decision tree model, some linear regression models, and a simple neural net.\n",
    "\n",
    "Fully and carefully evaluating the models should be done in test-model.ipynb, but there are some functions here to give a quick idea of whether the models are worth saving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72733c11-653e-4766-b1b6-72094af4dd20",
   "metadata": {},
   "source": [
    "## On predicting the logarithm instead of the wall time itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ace25-caae-433f-964a-c24142df97d9",
   "metadata": {},
   "source": [
    "We take this step to improve the quality of fit of the models. In order to use these regression models later for prediction (in apply_model.py and test_model.ipynb), we undo the logarithm by exponentiating the output of the model. This is the simplest way to undo the step of taking the logarithm, but perhaps not the best way, statistically speaking -- see the discussion [here](https://davegiles.blogspot.com/2013/08/forecasting-from-log-linear-regressions.html). This is an area for further improvement of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6148d-73e6-4825-93ab-c1bd66062b4f",
   "metadata": {},
   "source": [
    "# Notebook options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95a1de-0adc-4f11-bc6f-d6a0c3a2c260",
   "metadata": {},
   "source": [
    "There are 4 options for each model:\n",
    "\n",
    "1. 'train_model': Whether the notebook will train this type of model at all. If False, all other options can be ignored.\n",
    "\n",
    "2. 'grid_search': Whether the notebook will execute a grid search to find the best combination of hyperparameters. If False, the notebook will just use some pre-set parameters (which were found in previous grid searches). Note that grid search is not available for the neural net.\n",
    "\n",
    "3. 'training_mode': Either 'normal', 'test', or 'final'. Data is always split 50-25-25 into training, validation, and test sets. Models are always trained on the training set to begin with. This option indicates whether the model will train on the training data only ('normal' mode), the training data and the validation data ('test' mode), or all three datasets ('final' mode). Note that any extra training data (from validation/test sets) is only introduced at the very end, after the scaling of the X values, and after the grid search.\n",
    "\n",
    "4. 'save_model': Whether the model will be saved after fitting to the data. \n",
    "\n",
    "The random forest model has a fifth option:\n",
    "\n",
    "5. 'n_jobs': How many jobs to run in parallel for training. Only used during the grid search (otherwise this setting would persist when the model is saved). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2031b-7eb1-4b73-ac35-e35e46ede5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'tree':   {'train_model': True,\n",
    "                      'grid_search': True,\n",
    "                      'training_mode': 'normal',\n",
    "                      'save_model': False},\n",
    "           'forest': {'train_model': True,\n",
    "                      'grid_search': True,\n",
    "                      'training_mode': 'test',\n",
    "                      'save_model': True,\n",
    "                      'n_jobs': 1},\n",
    "           'gboost': {'train_model': True,\n",
    "                      'grid_search': True,\n",
    "                      'training_mode': 'test',\n",
    "                      'save_model': True},\n",
    "           'net':    {'train_model': False,\n",
    "                      'training_mode': 'normal',\n",
    "                      'save_model': False}\n",
    "          }\n",
    "\n",
    "tree_options = options['tree']\n",
    "forest_options = options['forest']\n",
    "gboost_options = options['gboost']\n",
    "net_options = options['net']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1bd63-3433-43f2-a8a8-e080eaa3965d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29148f7e-2410-4938-81bf-51fdcfc44148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from hypopt import GridSearch\n",
    "from preprocessing import get_df, scale\n",
    "from persistence import model_saver\n",
    "from evaluation import score_model, plot_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec469b0-a557-4f4f-b00e-de726adf258b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f4f6d-3842-4e24-9448-82bb22768955",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408b7cc-68f4-4298-bcf3-0b4b4fa868cd",
   "metadata": {},
   "source": [
    "Much of the general preprocessing work (used for both memory and time models) is handled in preprocessing.py. This includes adding composite features and handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623a8ed-44d0-41c4-8326-c48ea59172ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6410e571-caaa-4cf5-8e99-503ba6cb1335",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04a472-530e-44e9-bb62-e7d8e3c6d13a",
   "metadata": {},
   "source": [
    "All columns in X_features will be used to make predictions. \n",
    "\n",
    "y represents the data we'll be predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30de8c-9d70-4e62-a06c-ce96713d6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = ['PP', 'SP', 'BR', 'rqst_timespan', 'rqst_area_rect', 'converted',\n",
    "              'params_num', 'grid_def_num', 'level_num',\n",
    "              'ds084.1', 'ds631.1', 'ds083.3', 'ds094.0', 'ds083.2']\n",
    "y_features = ['wall_time']\n",
    "\n",
    "X = df[X_features]\n",
    "y = df[y_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a4030-f739-48b3-8e4b-ea83d3e7a8d0",
   "metadata": {},
   "source": [
    "## Train/validation/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce7991-3ae2-4969-a2ac-63efc5630e61",
   "metadata": {},
   "source": [
    "We split the data into training, validation, and testing sets according to the proportions in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00a03e-e1b4-445a-a108-08ff00bd1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amt = 0.5\n",
    "val_amt = 0.25\n",
    "test_amt = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc28f1-5a23-4e18-b516-ef835258bed9",
   "metadata": {},
   "source": [
    "It's not strictly necessary to create the 'y_train_full', 'y_val_full', etc. arrays here rather than simply 'y_train' and 'y_val', since they are not storing any extra information other than the information we want to predict. However, this keeps the arrays in the notebook named in the same way as the arrays in the other notebooks (time-classifiers.ipynb and mem-classifiers.ipynb), and that simplifies testing and predicting with the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db63f93-0f85-4924-9603-eb3d76b9f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_target, y_train_full, y_target_full = \\\n",
    "                train_test_split(X, y, \n",
    "                test_size=1-train_amt, \n",
    "                random_state = 3)\n",
    "X_val, X_test,y_val_full, y_test_full = \\\n",
    "                train_test_split(X_target, y_target_full,\n",
    "                                 test_size = test_amt/train_amt,\n",
    "                                 random_state = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63757e4b-fb07-4db9-8cad-b72a6ab1ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train_full)\n",
    "y_val = np.ravel(y_val_full)\n",
    "y_test = np.ravel(y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283dd0f6-3d4a-4786-a675-30cc0bc85f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y_train = np.log10(y_train)\n",
    "log_y_val = np.log10(y_val)\n",
    "log_y_test = np.log10(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90df84a-7187-40fa-85a1-e6ecd6b3091f",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1b2a9-f8ba-4932-880b-57d1d0446924",
   "metadata": {},
   "source": [
    "The scaling function is from preprocessing.py -- it scales the training, validation, and test input data according to the statistics of the training set only. (This is to prevent data leakage.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680a23c-1623-4f33-b51a-7ac338623ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm, X_val_norm, X_test_norm = \\\n",
    "        scale(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00c184-afe0-49d4-b41f-4fe124cd66ad",
   "metadata": {},
   "source": [
    "The data sets at our disposal now are:\n",
    "\n",
    "X_train, X_val, X_test: unscaled input data\n",
    "\n",
    "X_train_norm, X_val_norm, X_test_norm: scaled input data\n",
    "\n",
    "y_train, y_val, y_test: the output data we want to predict\n",
    "\n",
    "y_train_full, y_val_full, y_test_full: unused (see above)\n",
    "\n",
    "log_y_train, log_y_val, log_y_test: log base 10 of the data we want to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78406070-828c-4291-b725-5ffffdefd66b",
   "metadata": {},
   "source": [
    "## Trees and ensembles of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff99ed5-6561-4412-bc8a-6e805d237f5d",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b3e3f-9b0f-4b4e-b0aa-2f4964586a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tree_options['train_model'] and tree_options['grid_search']:\n",
    "    start = time.time()\n",
    "    tree_param_grid = {'random_state':[3], \n",
    "                       'max_depth':range(2,15),\n",
    "                       'min_samples_split':range(2,10)}\n",
    "    tree_gs = GridSearch(model=DecisionTreeRegressor(), \n",
    "                              param_grid=tree_param_grid,\n",
    "                              parallelize=False)\n",
    "    tree_gs.fit(X_train_norm, log_y_train, \n",
    "                X_val_norm, log_y_val)\n",
    "    \n",
    "    print(tree_gs.best_params)\n",
    "    tree = tree_gs.best_estimator_\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Time = {end-start}\")\n",
    "\n",
    "elif tree_options['train_model']:\n",
    "    tree = DecisionTreeRegressor(max_depth=14,\n",
    "                                 min_samples_split=2,\n",
    "                                 random_state=3)\n",
    "    tree.fit(X_train_norm, log_y_train)\n",
    "else:\n",
    "    tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba23fad-4a62-442a-9010-b611d64d2ecf",
   "metadata": {},
   "source": [
    "### Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43954ae6-66cb-45a3-b3b2-207fdce81d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if forest_options['train_model'] and forest_options['grid_search']:\n",
    "    start = time.time()\n",
    "    forest_param_grid = {'random_state':[3], \n",
    "                         'max_depth':range(2,15),\n",
    "                         'n_jobs':[forest_options['n_jobs']],\n",
    "                         'n_estimators':range(50,250,25),\n",
    "                         'min_samples_split':range(5,30,5)}\n",
    "    forest_gs = GridSearch(model=RandomForestRegressor(), \n",
    "                                param_grid=forest_param_grid,\n",
    "                                parallelize=False)\n",
    "    forest_gs.fit(X_train_norm, log_y_train, \n",
    "                  X_val_norm, log_y_val)\n",
    "    end = time.time()\n",
    "    print(f\"Time = {end-start}\")\n",
    "    print(forest_gs.best_params)\n",
    "    forest = forest_gs.best_estimator_\n",
    "    \n",
    "elif forest_options['train_model']:\n",
    "    forest_params = {'max_depth': 14, \n",
    "                     'n_estimators': 250,\n",
    "                     'min_samples_split':5, \n",
    "                     'random_state': 3}\n",
    "    \n",
    "    forest = RandomForestRegressor(**forest_params)\n",
    "    forest.fit(X_train_norm, log_y_train)\n",
    "    \n",
    "else:\n",
    "    forest = RandomForestRegressor() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d4656-05ba-4ad6-a25e-93c93a50504e",
   "metadata": {},
   "source": [
    "### Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b78db-9b7f-4c96-8111-526e17233ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gboost_options['train_model'] and gboost_options['grid_search']:\n",
    "    start = time.time()\n",
    "    gboost_param_grid = {'random_state':[3],\n",
    "                         'max_depth':range(2,15),\n",
    "                         'n_estimators':range(50,300,50)}\n",
    "    gboost_gs = GridSearch(model=GradientBoostingRegressor(), \n",
    "                                param_grid=gboost_param_grid,\n",
    "                                parallelize=False)\n",
    "    gboost_gs.fit(X_train_norm, log_y_train, \n",
    "                  X_val_norm, log_y_val)\n",
    "    \n",
    "    print(gboost_gs.best_params)\n",
    "    gboost = gboost_gs.best_estimator_\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Time = {end-start}\")\n",
    "elif gboost_options['train_model']:\n",
    "    gboost = GradientBoostingRegressor(random_state=3,\n",
    "                                        max_depth=14,\n",
    "                                        n_estimators=150)\n",
    "    gboost.fit(X_train_norm, log_y_train)\n",
    "else:\n",
    "    gboost = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db0eb7-a3b1-4c87-9615-e7f40c823908",
   "metadata": {},
   "source": [
    "## Neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200d02c-457a-4e84-93f2-8f15e98b17df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = MLPRegressor(random_state=3,\n",
    "                   hidden_layer_sizes=(200,200,200,200),\n",
    "                   max_iter=500)\n",
    "\n",
    "if net_options['train_model']:\n",
    "    net.fit(X_train_norm, log_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455f6f3-de88-494a-bbf8-fd60c58fdb5e",
   "metadata": {},
   "source": [
    "# Extra training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07749be2-4edc-4ec3-b994-72474fd15fed",
   "metadata": {},
   "source": [
    "This section trains the models on extra data if their training_mode option is set to either 'test' or 'final'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde0749-8627-4852-83b8-506e83157cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'tree': tree,\n",
    "               'forest': forest,\n",
    "               'gboost': gboost,\n",
    "               'net': net}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33276456-8a89-4d2d-9ee2-d9d675c71629",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode_X_train_norm = np.concatenate((X_train_norm, X_val_norm))\n",
    "test_mode_y_train = np.concatenate([log_y_train,\n",
    "                                  log_y_val])\n",
    "\n",
    "final_mode_X_train_norm = np.concatenate((X_train_norm,\n",
    "                              X_val_norm,\n",
    "                              X_test_norm))\n",
    "final_mode_y_train = np.concatenate([log_y_train,\n",
    "                                  log_y_val,\n",
    "                                  log_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80a715-8e45-4a8c-b57d-66d32a286e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models_dict:\n",
    "    if options[model_name]['train_model']:\n",
    "        if options[model_name]['training_mode'] == 'test':\n",
    "            models_dict[model_name].fit(test_mode_X_train_norm,\n",
    "                                        test_mode_y_train)\n",
    "        elif options[model_name]['training_mode'] == 'final':\n",
    "            models_dict[model_name].fit(final_mode_X_train_norm,\n",
    "                                        final_mode_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d74a9-25e2-4b56-b554-38909d85d8d4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c79a4-9c2a-495e-a539-193367776b20",
   "metadata": {},
   "source": [
    "Here we make some simple graphs and reports to give an idea whether our models are worth saving. Note that all figures and reports are done using the validation data -- if the models are set to 'test' or 'final' training modes, they will have already trained on this data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422212b-5795-487b-a6ea-bbf646a09ebf",
   "metadata": {},
   "source": [
    "The score printed by the next cell is the R^2 coefficient, defined as 1 - u/v, where u is the sum over all samples of (y_true - y_pred)^2, and v is the sum over all samples of (y_true - y_mean)^2. \n",
    "\n",
    "The best possible score is 1.0, and scores can be negative, indicating that the model is worse than just always predicting the average wall time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2ddd6-fea4-46d8-b734-d0880df99062",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models_dict:\n",
    "    if options[model_name]['train_model']:\n",
    "        print(model_name+':')\n",
    "        score_model(X_train_norm, log_y_train, \n",
    "                    X_val_norm, log_y_val, \n",
    "                    models_dict[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad59417-edc8-44ff-870c-58200cf3f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models_dict:\n",
    "    if options[model_name]['train_model']:\n",
    "        plot_performance(X_val_norm, log_y_val, \n",
    "                         models_dict[model_name],\n",
    "                         model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad1e52-ac37-48dd-ad14-12052b654aee",
   "metadata": {},
   "source": [
    "# Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b58d37-c741-4924-946d-fb55d61a4b13",
   "metadata": {},
   "source": [
    "This section saves the models using the model_saver object from persistence.py. We begin by creating a 'notes' string for each model we intend to save, which by default just specifies which notebook options were used for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce14cff-9000-4970-8048-742f41d33828",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_names = {'tree': 'Decision Tree Regressor',\n",
    "                    'forest': 'Random Forest Regressor',\n",
    "                    'gboost': 'Gradient Boosting Regressor',\n",
    "                    'net': 'Multi-layer Perceptron Regressor'}\n",
    "\n",
    "training_data_names = {'normal': 'training',\n",
    "                       'test': 'training and validation',\n",
    "                       'final': 'training, validation, and testing'}\n",
    "\n",
    "model_notes = {}\n",
    "\n",
    "for model_name in models_dict:\n",
    "    if options[model_name]['train_model'] and options[model_name]['save_model']:\n",
    "        data_name = training_data_names[options[model_name]['training_mode']]\n",
    "        grid_search = options[model_name]['grid_search']\n",
    "        notes = f\"{full_model_names[model_name]}. \" \\\n",
    "                 + f\"Trained on {data_name} data. \" \\\n",
    "                 + f\"Grid search {'not ' if not grid_search else ''}performed. \" \\\n",
    "                 + \"X values NOT scaled.\"\n",
    "        model_notes[model_name] = notes\n",
    "        \n",
    "print(model_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02849c48-a353-4492-803b-0e111c3a955a",
   "metadata": {},
   "source": [
    "Now we save all the desired models. Note that by passing folder_path=None as a parameter to the model_saver object, models will be saved at the default path found in persistence.py, that is, /glade/work/jdubeau/model-saves/.\n",
    "\n",
    "This creates a folder for each model, e.g. /glade/work/jdubeau/model-saves/time_regr_forest_test2021-07-01-16:04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6574e-5c50-4d30-816b-a5da11addda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models_dict:\n",
    "    if options[model_name]['train_model'] and options[model_name]['save_model']:\n",
    "        save_name = 'time_regr_' \\\n",
    "                    + model_name \\\n",
    "                    + '_' \\\n",
    "                    + options[model_name]['training_mode']\n",
    "        ms = model_saver(save_name, \n",
    "                         model_notes[model_name],\n",
    "                         models_dict[model_name], \n",
    "                         df, \n",
    "                         categories_dict,\n",
    "                         X_features,\n",
    "                         X_train, y_train_full,\n",
    "                         X_val, y_val_full,\n",
    "                         X_test, y_test_full,\n",
    "                         folder_path=None)\n",
    "        ms.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
